{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cq6PdPGN4DJu"
   },
   "source": [
    "# Triplet Loss with Faces -- Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2r4GrySt26Q-",
    "outputId": "4890c780-31f1-4532-d4a7-64f7412ea780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from torch) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "elsPIhAzrPL-",
    "outputId": "486d7b03-5889-4c28-c71e-b1e169f7e026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mat73 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (0.58)\n",
      "Requirement already satisfied: numpy in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from mat73) (1.21.2)\n",
      "Requirement already satisfied: h5py in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from mat73) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mat73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (4.63.0)\n",
      "Requirement already satisfied: pandas in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (1.4.1)\n",
      "Requirement already satisfied: scikit-learn in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (1.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from pandas) (1.21.2)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-learn) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (0.19.2)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (1.21.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (9.0.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from scikit-image) (2.7.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/mgornet/anaconda3/envs/face_reco/lib/python3.9/site-packages (from packaging>=20.0->scikit-image) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FyTWhJXMpRex",
    "outputId": "dcfa38a7-4bd7-4b6b-e6b4-d96298974042"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "N2ZqMDMrKeFi",
    "outputId": "6ddb3d01-83e5-4bb2-a378-54748c3c742c"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/mgornet/CNPEN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MW_MVwhYwRiH"
   },
   "source": [
    "### Check device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "zruTnsd7wTz6",
    "outputId": "66c9d4a5-2768-45b6-d901-16ab0b7d9081"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 22 10:46:23 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.85.02    Driver Version: 510.85.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A400...  Off  | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   58C    P8    21W /  N/A |   7935MiB /  8192MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      1756      G   /usr/lib/xorg/Xorg                 65MiB |\n",
      "|    0   N/A  N/A      2625      G   /usr/lib/xorg/Xorg                158MiB |\n",
      "|    0   N/A  N/A      2754      G   /usr/bin/gnome-shell               61MiB |\n",
      "|    0   N/A  N/A      6474      G   ...411073793531784828,131072       84MiB |\n",
      "|    0   N/A  N/A     12080      C   ...envs/face_reco/bin/python     2609MiB |\n",
      "|    0   N/A  N/A     12857      C   ...envs/face_reco/bin/python     3225MiB |\n",
      "|    0   N/A  N/A     13445      C   ...envs/face_reco/bin/python     1719MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda available:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"cuda available: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda version:  11.3\n"
     ]
    }
   ],
   "source": [
    "print(\"cuda version: \", torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch config:  PyTorch built with:\n",
      "  - GCC 7.3\n",
      "  - C++ Version: 201402\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2021.4-Product Build 20210904 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.5.2 (Git Hash a9302535553c73243c632ad3c4c80beec3d19a1e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.3\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=compute_37\n",
      "  - CuDNN 8.2\n",
      "  - Magma 2.5.2\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.3, CUDNN_VERSION=8.2.0, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.11.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=OFF, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"torch config: \", torch.__config__.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJK8gGmS4dsb"
   },
   "source": [
    "### Import Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JyM1GtzC2_zh"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from time import perf_counter\n",
    "from typing import Callable\n",
    "import itertools\n",
    "import mat73\n",
    "import pandas as pd\n",
    "import re\n",
    "import wandb\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tarfile\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import os.path as op\n",
    "try:\n",
    "    from urllib.request import urlretrieve\n",
    "except ImportError:  # Python 2 compat\n",
    "    from urllib import urlretrieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeds set for training phase\n"
     ]
    }
   ],
   "source": [
    "seed = 121\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "print ('Seeds set for training phase')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ix4Yn3BoLNfx",
    "outputId": "7947880c-ab47-4393-c5d6-be37199febe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mgornet/Bureau/Code/CNPEN/files\n"
     ]
    }
   ],
   "source": [
    "%cd ./files\n",
    "# ./CNPEN/files\n",
    "\n",
    "from triplet import TripletGenerator, TripletLearner, TripletLoss, TripletLossRaw\n",
    "from builder import create_dataframe, from_tensor_to_numpy, from_numpy_to_tensor, extend_dataframe\n",
    "from prints import print_img, print_img_from_path, print_img_from_id, print_img_from_classid, print_from_gen, print_from_gen2, print_pair, print_hist_loss, print_hist_dist, print_img_category\n",
    "from test_train_loops import training, testing, adaptative_train, compute_distances # adaptative_train_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "dNWBFp1aLev5",
    "outputId": "780215a4-2505-447d-86e6-385dd44f016e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mgornet/Bureau/Code/CNPEN/files\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hp8S6_Nu4muA"
   },
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "0HQV0dwQiLvS",
    "outputId": "343cfafa-cadf-4554-f5a1-90e52f96afca"
   },
   "outputs": [],
   "source": [
    "URL = \"http://vis-www.cs.umass.edu/lfw/lfw-deepfunneled.tgz\"\n",
    "FILENAME = \"lfw-deepfunneled.tgz\"\n",
    "\n",
    "if not op.exists(FILENAME):\n",
    "    print('Downloading %s to %s...' % (URL, FILENAME))\n",
    "    urlretrieve(URL, FILENAME)\n",
    "\n",
    "if not op.exists(\"lfw\"):\n",
    "    print('Extracting image files...')\n",
    "    tar = tarfile.open(\"lfw-deepfunneled.tgz\")\n",
    "    tar.extractall(\"lfw\")\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "jtFwuCt4iSgy"
   },
   "outputs": [],
   "source": [
    "PATH = \"lfw/lfw-deepfunneled/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pW3OOgQXOLa-",
    "outputId": "8cb4ccff-40ca-44aa-b9f0-3e7244731cfe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals:  5749\n",
      "Number of total images:  13233\n",
      "images weigh  0.57 GB\n",
      "DataFrame creation: 1.3 min\n"
     ]
    }
   ],
   "source": [
    "tic = perf_counter()\n",
    "df_init, all_imgs = create_dataframe()\n",
    "toc = perf_counter()\n",
    "print(f\"DataFrame creation: {((toc - tic)/60):.1f} min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame extention: 0.1 min\n"
     ]
    }
   ],
   "source": [
    "tic = perf_counter()\n",
    "df = extend_dataframe(df_init)\n",
    "toc = perf_counter()\n",
    "print(f\"DataFrame extention: {((toc - tic)/60):.1f} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gjPcX2sdTQz4"
   },
   "source": [
    "### Build sets, generators and network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "9YhsU5iYDx0c",
    "outputId": "fe319f34-b66f-4601-d05c-25dabcaa1656"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals:  5749\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df.Classid.unique())\n",
    "print(\"Number of individuals: \", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SX80fCGkn702"
   },
   "outputs": [],
   "source": [
    "indiv_min = df.Classid.min()\n",
    "split_train_valid = int(num_classes * 0.75)\n",
    "split_train_test = int(num_classes * 0.8)\n",
    "indiv_max = df.Classid.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "1rHLE3kHcCyp",
    "outputId": "5291153a-b4d0-4bf5-d690-25979aafaeee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set from indiv 0 to 4310\n",
      "Valid set from indiv 4311 to 4598\n",
      "Test set from indiv 4599 to 5748\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train set from indiv {indiv_min} to {split_train_valid-1}\")\n",
    "print(f\"Valid set from indiv {split_train_valid} to {split_train_test-1}\")\n",
    "print(f\"Test set from indiv {split_train_test} to {indiv_max}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "P0vpXVlscwOA"
   },
   "outputs": [],
   "source": [
    "df_train = df[df.Classid<split_train_valid]\n",
    "df_valid = df[(df.Classid>=split_train_valid)&(df.Classid<split_train_test)]\n",
    "df_test = df[df.Classid>=split_train_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "6y6Lmu7UTQz6",
    "outputId": "28af2b3b-e25e-4e31-d548-10f4f98de50e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images:  10060\n",
      "Number of validation images:  586\n",
      "Number of testing images:  2587\n",
      "Number of total images:  13233\n",
      "len original:  13233\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training images: \", len(df_train))\n",
    "print(\"Number of validation images: \", len(df_valid))\n",
    "print(\"Number of testing images: \", len(df_test))\n",
    "print(\"Number of total images: \", len(df_train)+len(df_valid)+len(df_test))\n",
    "print(\"len original: \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "LeMZhCJtTQz6",
    "outputId": "a253f6dc-6c2e-4ae6-d2f3-5be83a67603d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals in the training set:  4311\n",
      "Number of individuals in the validation set:  288\n",
      "Number of individuals in the testing set:  1150\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of individuals in the training set: \", len(df_train.Classid.unique()))\n",
    "print(\"Number of individuals in the validation set: \", len(df_valid.Classid.unique()))\n",
    "print(\"Number of individuals in the testing set: \", len(df_test.Classid.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "44sct3lGTQz7",
    "outputId": "f430af11-01cd-4696-eedf-f9e66aca0a4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of individuals with more than one image in the training set:  1267\n",
      "Number of individuals with more than one image in the validation set:  79\n",
      "Number of individuals with more than one image in the testing set:  334\n"
     ]
    }
   ],
   "source": [
    "value_count = df_train.Classid.value_counts()\n",
    "print(\"Number of individuals with more than one image in the training set: \", len(value_count[value_count.values>1]))\n",
    "value_count = df_valid.Classid.value_counts()\n",
    "print(\"Number of individuals with more than one image in the validation set: \", len(value_count[value_count.values>1]))\n",
    "value_count = df_test.Classid.value_counts()\n",
    "print(\"Number of individuals with more than one image in the testing set: \", len(value_count[value_count.values>1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "nkVW9HZq9K9e",
    "outputId": "cd5adc42-7ad9-468a-8aee-9039c7cc30d9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classid</th>\n",
       "      <th>Name</th>\n",
       "      <th>Path</th>\n",
       "      <th>Male</th>\n",
       "      <th>Asian</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>Baby</th>\n",
       "      <th>Child</th>\n",
       "      <th>Youth</th>\n",
       "      <th>...</th>\n",
       "      <th>Pale Skin</th>\n",
       "      <th>5 o Clock Shadow</th>\n",
       "      <th>Strong Nose-Mouth Lines</th>\n",
       "      <th>Wearing Lipstick</th>\n",
       "      <th>Flushed Face</th>\n",
       "      <th>High Cheekbones</th>\n",
       "      <th>Brown Eyes</th>\n",
       "      <th>Wearing Earrings</th>\n",
       "      <th>Wearing Necktie</th>\n",
       "      <th>Wearing Necklace</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10060</th>\n",
       "      <td>4311</td>\n",
       "      <td>Pedro_Solbes</td>\n",
       "      <td>Pedro_Solbes/Pedro_Solbes_0001.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10061</th>\n",
       "      <td>4311</td>\n",
       "      <td>Pedro_Solbes</td>\n",
       "      <td>Pedro_Solbes/Pedro_Solbes_0002.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10062</th>\n",
       "      <td>4311</td>\n",
       "      <td>Pedro_Solbes</td>\n",
       "      <td>Pedro_Solbes/Pedro_Solbes_0003.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10063</th>\n",
       "      <td>4311</td>\n",
       "      <td>Pedro_Solbes</td>\n",
       "      <td>Pedro_Solbes/Pedro_Solbes_0004.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10064</th>\n",
       "      <td>4312</td>\n",
       "      <td>Pedro_Velasquez</td>\n",
       "      <td>Pedro_Velasquez/Pedro_Velasquez_0001.jpg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Classid             Name                                      Path  \\\n",
       "10060     4311     Pedro_Solbes        Pedro_Solbes/Pedro_Solbes_0001.jpg   \n",
       "10061     4311     Pedro_Solbes        Pedro_Solbes/Pedro_Solbes_0002.jpg   \n",
       "10062     4311     Pedro_Solbes        Pedro_Solbes/Pedro_Solbes_0003.jpg   \n",
       "10063     4311     Pedro_Solbes        Pedro_Solbes/Pedro_Solbes_0004.jpg   \n",
       "10064     4312  Pedro_Velasquez  Pedro_Velasquez/Pedro_Velasquez_0001.jpg   \n",
       "\n",
       "       Male  Asian  White  Black  Baby  Child  Youth  ...  Pale Skin  \\\n",
       "10060   1.0    0.0    1.0    0.0   0.0    0.0    0.0  ...        0.0   \n",
       "10061   1.0    0.0    1.0    0.0   0.0    0.0    0.0  ...        0.0   \n",
       "10062   1.0    0.0    1.0    0.0   0.0    0.0    0.0  ...        0.0   \n",
       "10063   1.0    0.0    1.0    0.0   0.0    0.0    0.0  ...        1.0   \n",
       "10064   1.0    0.0    1.0    0.0   0.0    0.0    0.0  ...        1.0   \n",
       "\n",
       "       5 o Clock Shadow  Strong Nose-Mouth Lines  Wearing Lipstick  \\\n",
       "10060               1.0                      1.0               0.0   \n",
       "10061               1.0                      1.0               0.0   \n",
       "10062               1.0                      0.0               0.0   \n",
       "10063               1.0                      1.0               0.0   \n",
       "10064               1.0                      1.0               0.0   \n",
       "\n",
       "       Flushed Face  High Cheekbones  Brown Eyes  Wearing Earrings  \\\n",
       "10060           0.0              1.0         1.0               0.0   \n",
       "10061           0.0              0.0         1.0               0.0   \n",
       "10062           0.0              0.0         1.0               0.0   \n",
       "10063           0.0              0.0         1.0               0.0   \n",
       "10064           0.0              0.0         0.0               0.0   \n",
       "\n",
       "       Wearing Necktie  Wearing Necklace  \n",
       "10060              1.0               0.0  \n",
       "10061              1.0               0.0  \n",
       "10062              1.0               0.0  \n",
       "10063              0.0               0.0  \n",
       "10064              1.0               0.0  \n",
       "\n",
       "[5 rows x 76 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "otF4YNywkl2O"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128 # 128\n",
    "BATCH_VALID_SIZE = 8 #128 #8\n",
    "BATCH_TEST_SIZE = 32 #128 #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "IhO6Pj2q3tnM"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m TripletLearner(base_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m lr \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-3\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m#1e-3\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# optimizer = optim.Adam(model.parameters(), lr=lr)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/face_reco/lib/python3.9/site-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/face_reco/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/face_reco/lib/python3.9/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/face_reco/lib/python3.9/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/face_reco/lib/python3.9/site-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = TripletLearner(base_channels=32, dropout=0)\n",
    "model.to(device)\n",
    "\n",
    "lr = 1e-3/2 #1e-3\n",
    "# optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[300,400,500,600,700,800,900], gamma=0.5) #milestones=[100,200,300,400]\n",
    "\n",
    "margin = 0.2\n",
    "criterion = TripletLoss(margin)\n",
    "criterion_test = TripletLossRaw(margin)\n",
    "\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTlnqfzSHdcs",
    "outputId": "62c14507-108e-4259-c5af-7477431e189b"
   },
   "outputs": [],
   "source": [
    "gen_train = TripletGenerator(df_train, all_imgs, BATCH_SIZE, device, model, margin, transform = False)#, mining='standard')\n",
    "train_loader = DataLoader(gen_train, batch_size=None, shuffle=True, num_workers=8)\n",
    "\n",
    "gen_valid = TripletGenerator(df_valid, all_imgs, BATCH_VALID_SIZE, device, model, margin)\n",
    "valid_loader = DataLoader(gen_valid, batch_size=None, shuffle=True, num_workers=8)\n",
    "\n",
    "gen_test = TripletGenerator(df_test, all_imgs, BATCH_TEST_SIZE, device, model, margin)\n",
    "test_loader = DataLoader(gen_test, batch_size=None, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_5m3ZL2xOk5"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sjPKzFRUxS6P"
   },
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I6MxLGSuwtLR"
   },
   "outputs": [],
   "source": [
    "wandb.init(project=\"triplet_faces\",\n",
    "           name=\"no_augment2\",\n",
    "           config={\"seed\" : seed,\n",
    "                  \"batch_size\": BATCH_SIZE,\n",
    "                  \"margin\": margin,\n",
    "                  \"nb epochs\": epochs,\n",
    "                  \"learning_rate\" : lr,\n",
    "                  \"scheduler\" : scheduler,\n",
    "                  \"optimizer\" : optimizer,\n",
    "#                   \"criterion\" : \"euclidean square\",\n",
    "                  \"dataset\": \"LFW\",\n",
    "                  \"network_base_channels\": model.base_channels,\n",
    "                  \"augment\": gen_train.transform,\n",
    "                   \"augmentation\": gen_train.apply_augmentation,\n",
    "                  \"dropout\": model.dropout,\n",
    "                  \"mining\": gen_train.mining})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TUs4s6c74A_t"
   },
   "outputs": [],
   "source": [
    "model = training(model, device, optimizer, scheduler, criterion, epochs, train_loader, valid_loader, save_epoch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKega-doiHpU"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './'+wandb.run.name+'.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='./CNPEN/files/high_jitter.pth'> Download File </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sH6Uj-ayCzEo"
   },
   "outputs": [],
   "source": [
    "if wandb.run is not None:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
